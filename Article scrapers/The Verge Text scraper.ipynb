{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os.path\n",
    "from htmldate import find_date\n",
    "import pandas as pd\n",
    "def scrape(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception:\n",
    "        return \"DELETE\"\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'lxml')  # You can also use 'html.parser'\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    testArticle= soup.find_all(\"a\")\n",
    "    article = True\n",
    "    for t in testArticle:\n",
    "        try:\n",
    "            if t[\"href\"] ==\"#comments\":\n",
    "                return \"DELETE\"\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    textOut = \"\"\n",
    "    try:\n",
    "        timeStamp = find_date(url)\n",
    "        year = timeStamp.split(\"-\")[0]\n",
    "        month = timeStamp.split(\"-\")[1]\n",
    "        day = timeStamp.split(\"-\")[2]\n",
    "    except Exception:\n",
    "        year = \"check\"\n",
    "        month = \"check\"\n",
    "        day = \"check\"\n",
    "    if year == \"check\":\n",
    "        findDate = url.split(\"/\")\n",
    "        dateList = []\n",
    "        for index,f in enumerate(findDate):\n",
    "            if f in [2016,2017,2018,2019,2020,2021]:\n",
    "                for i in range(index,index+3):\n",
    "                        dateList.append(findDate[i])\n",
    "                        print(dateList[-1])\n",
    "                year = dateList[0]\n",
    "                month = dateList[1]\n",
    "                day = dateList[2]\n",
    "                break\n",
    "        \n",
    "    removeList = []\n",
    "    remove = soup.find_all(\"div\",class_=\"mb-2 text-blurple [&>p>span:first-child]:text-gray-13 [&_.duet--article-byline-and]:text-gray-13\")\n",
    "    moreRemove = soup.find_all(\"div\",{\"class\":\"mb-2\"})\n",
    "    for m in moreRemove:\n",
    "        removeList.append(m.get_text().strip().replace(\"\\n\",\"\"))\n",
    "    removeList = []\n",
    "    for r in remove:\n",
    "        removeList.append(r.get_text().strip().replace(\"\\n\",\"\"))\n",
    "    text = soup.find_all(\"p\")\n",
    "    removeList.extend([\"/ Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.\",\"The Verge is a vox media network\",\"© 2024 Vox Media, LLC. All Rights Reserved\",\n",
    "                        \"If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.\",\"The interview has been condensed and edited.\"])\n",
    "    for block,p in enumerate(paragraphs):\n",
    "        text = p.get_text().replace(\"\\n\",\"\").strip()\n",
    "        if text != \"\" and text[-1] in '!.?:)”\"' and text not in removeList and  not (block==0 and \"By  \" in text) and (\"Sign up here.\" not in text and \"Platformer\" not in text) and not (text[0:10]==\"Correction\" and block!=len(paragraphs)-1 and paragraphs[block+1].get_text().strip().replace(\"\\n\",\"\") in [\"/ Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.\",\"The Verge is a vox media network\",\"© 2024 Vox Media, LLC. All Rights Reserved\"]): #this varies between websites since some write in a more academic manner\n",
    "            textOut+= \" \" + text\n",
    "    \n",
    "    length = 0\n",
    "    if textOut == \"\":\n",
    "        return \"DELETE\"\n",
    "    else:\n",
    "        length = len(textOut.split())\n",
    "        return [url,\"Wired\",year,month,day,length,textOut]\n",
    "df = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
