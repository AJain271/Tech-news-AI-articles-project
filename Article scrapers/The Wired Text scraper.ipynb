{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from htmldate import find_date\n",
    "import pandas as pd\n",
    "def scrape(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception:\n",
    "        return \"DELETE\"\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'lxml')  # You can also use 'html.parser'\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    textOut = \"\"\n",
    "    timeStamp = \"\"\n",
    "    try:\n",
    "        timeStamp = find_date(url)\n",
    "        year = timeStamp.split(\"-\")[0]\n",
    "        month = timeStamp.split(\"-\")[1]\n",
    "        day = timeStamp.split(\"-\")[2]\n",
    "    except Exception:\n",
    "        year = \"check\"\n",
    "        month = \"check\"\n",
    "        day = \"check\"\n",
    "    captions = soup.find_all(\"span\")\n",
    "    otherRemove = soup.find_all(\"div\",{\"class\":\"GenericCalloutWrapper-tojWn bPlNqk callout--has-top-border\"})\n",
    "    oRemoveList = []\n",
    "    for o in otherRemove:\n",
    "        oRemoveList.append(o.get_text().replace(\"\\n\",\"\"))\n",
    "    capList = []\n",
    "    lastspan = \"\"\n",
    "    if len(captions) != 0:\n",
    "        for c in captions:\n",
    "            caption = c.get_text().replace(\"\\n\",\"\")\n",
    "            if caption ==\"\":\n",
    "                continue\n",
    "            if caption[-1] in \"!.?\":\n",
    "                capList.append(caption)\n",
    "                continue\n",
    "            if \"Courtesy of\" in caption or \"Photograph\" in caption:\n",
    "                if lastspan not in capList:\n",
    "                    capList.append(lastspan)\n",
    "            lastspan = caption\n",
    "    about = False\n",
    "    \n",
    "    removeList = [\"© 2024 Condé Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices\",\n",
    "                    \"More From WIRED\",\"Reviews and Guides\",\"To revisit this article, visit My Profile, then View saved stories.\",\"Related Wired coverage here.\",\"If you buy something using links in our stories, we may earn a commission. Learn more.\",\"WIRED Opinion publishes articles by outside contributors representing a wide range of viewpoints. Read more opinions here, and see our submission guidelines here. Submit an op-ed at opinion@wired.com.\",\n",
    "                    \"SUPPORT REQUEST :\"]  \n",
    "    for p in paragraphs:\n",
    "        about = False\n",
    "    \n",
    "        text = p.get_text().replace(\"\\n\",\"\").strip()\n",
    "        #print(text)\n",
    "        if \"Scoop:\" in text  or \"How did coronavirus start and what happens next?\" in text or \"More From WIRED\" == text:\n",
    "            break\n",
    "        for j in oRemoveList:\n",
    "            if text in j:\n",
    "                about = True\n",
    "                break\n",
    "        if len(text) >1 and text not in removeList and text[-1] in '!.?:”))\"' and \"Read more: \" not in text and text not in capList and not about:\n",
    "            if paragraphs.index(p)< len(paragraphs)-1:\n",
    "                nextLine = paragraphs[paragraphs.index(p)+1].get_text().replace(\"\\n\",\"\").strip()\n",
    "            if (paragraphs.index(p)< len(paragraphs)-1 and \"Updated, \" in text and (nextLine ==\"More From WIRED\" or \"Updated, \" in  nextLine)) or (paragraphs.index(p)< len(paragraphs)-1 and \"Correction: \" in text and (\"Scoop:\" in nextLine or nextLine ==\"More from WIRED\")):\n",
    "                break\n",
    "            textOut+= \" \" + text\n",
    "    length = 0\n",
    "    if textOut == \"\":\n",
    "        return \"DELETE\"\n",
    "    else:\n",
    "        length = len(textOut.split())\n",
    "        return [url,\"Wired\",year,month,day,length,textOut]\n",
    "df = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
